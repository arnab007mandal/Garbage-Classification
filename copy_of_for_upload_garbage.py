# -*- coding: utf-8 -*-
"""Copy of For_Upload_Garbage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IhPkFpPUYAVfe_GkLcz-3-0DFL4OMtJs

Importing the required libraries
"""

import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense
from keras.models import Sequential
import glob, os, random
import tensorflow as tf

"""Getting the images to train and test our model."""

base_path = '/content/drive/MyDrive/Data Science/Garbage_Classification OLD FILE '

img_list = glob.glob(os.path.join(base_path, '*/*.jpg'))

print(len(img_list))

img_height,img_width=224,224
batch_size=1
# Training Dataset
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/drive/MyDrive/Data Science/Garbage_Classification OLD FILE ',
  
  image_size=(img_height, img_width),
  batch_size=batch_size)

#Classes Identification
class_names = train_ds.class_names
num_classes=len(class_names)
print(class_names,num_classes)

from PIL import Image
for i, img_path in enumerate(random.sample(img_list, 10)):
    img = load_img(img_path)
    img = img_to_array(img, dtype=np.uint8)

    plt.subplot(6, 3, i+1)
    plt.imshow(img.squeeze())

"""Preparing Image data from the directory:"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.1
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1
)

train_generator = train_datagen.flow_from_directory(
    base_path,
    target_size=(300, 300),
    batch_size=16,
    class_mode='categorical',
    subset='training',
    seed=0
)

validation_generator = test_datagen.flow_from_directory(
    base_path,
    target_size=(300, 300),
    batch_size=16,
    class_mode='categorical',
    subset='validation',
    seed=0
)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())

print(labels)

"""Building the Neural Network:"""

model = Sequential([
    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),
    MaxPooling2D(pool_size=2),

    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),

    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),

    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),

    Flatten(),

    Dense(64, activation='relu'),

    Dense(6, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])

model.summary()

"""Fit the date in the model to train and validate."""

hist=model.fit_generator(train_generator, epochs=5, validation_data=validation_generator)

test_x, test_y = validation_generator.__getitem__(1)

preds = model.predict(test_x)

plt.figure(figsize=(16, 16))
for i in range(16):
    plt.subplot(4, 4, i+1)
    plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))
    plt.imshow(test_x[i])

"""Making predictions with the model"""

predicted= []
actual = []
for i in range(16):
    predicted.append(labels[np.argmax(preds[i])])
    actual.append(labels[np.argmax(test_y[i])])

import pandas as pd
df = pd.DataFrame(predicted, columns=["predicted"])
df["actual"] = actual
df

tf.keras.models.save_model(model,'GarbagePred.hdf5')